{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethel-Ogallo/multitask_regression_deeplearning/blob/master/Multi_task_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "343d83c4",
      "metadata": {
        "id": "343d83c4"
      },
      "source": [
        "## Multi-Task Regression Using ResNet50\n",
        "\n",
        "This notebook demonstrates a **supervised multi-task regression** workflow for remote sensing using **TorchGeo** using the Digital Typhoon dataset, which consists of infrared (IR) satellite imagery of tropical cyclones paired with meteorological measurements.\n",
        "\n",
        "The objective is to predict multiple continuous typhoon intensity variables from satellite imagery using a deep learning model.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa406dec-9786-4a3a-bb24-71a692843e0f",
      "metadata": {
        "id": "fa406dec-9786-4a3a-bb24-71a692843e0f"
      },
      "source": [
        "### Dataset Overview\n",
        "The [Digital Typhoon](https://torchgeo.readthedocs.io/en/stable/api/datasets.html#digital-typhoon) is derived from hourly infrared channel observations captured by multiple generations of the Himawari meteorological satellites, spanning the period from 1978. The satellite measurements have been converted to brightness temperatures and normalized across different sensors, resulting in a consistent spatio-temporal dataset covering more than four decades.  \n",
        "\n",
        "**Dataset features:**\n",
        "- Infrared (IR) satellite imagery of 512 × 512 pixels at ~5km resolution\n",
        "- Auxiliary metadata including wind speed, pressure and additional typhoon-related attributes  \n",
        "- 1,099 typhoons and 189,364 images\n",
        "\n",
        "**References**  \n",
        "1. Machine Learning for the Digital Typhoon Dataset:\n",
        "Extensions to Multiple Basins and New Developments\n",
        "in Representations and Tasks: [arXiv:2411.16421](https://arxiv.org/pdf/2411.16421)  \n",
        "2. Digital Typhoon: Long-term Satellite Image Dataset\n",
        "for the Spatio-Temporal Modeling of Tropical Cyclones: [arXiv:2311.02665](https://arxiv.org/pdf/2311.02665)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*notes from paper:*  \n",
        "*the images feature a 2D array of brightness temperatures around the typhoon’s center, formatted in HDF5*"
      ],
      "metadata": {
        "id": "NZMWBXftSDG6"
      },
      "id": "NZMWBXftSDG6"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VSeRurN3cm-",
        "outputId": "453daee8-9443-4ef7-d3d5-bd5c19513b76"
      },
      "id": "2VSeRurN3cm-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchgeo --quiet\n",
        "!pip install wandb --quiet"
      ],
      "metadata": {
        "id": "fuWdYpGH3gDF"
      },
      "id": "fuWdYpGH3gDF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cfcd2e0",
      "metadata": {
        "id": "4cfcd2e0"
      },
      "outputs": [],
      "source": [
        "## import package\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "from torchgeo.datasets import DigitalTyphoon\n",
        "from torchgeo.datamodules import DigitalTyphoonDataModule\n",
        "from torchgeo.trainers import RegressionTask\n",
        "from torchgeo.models import resnet50, ResNet50_Weights\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from lightning.pytorch.loggers import WandbLogger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f21ec6",
      "metadata": {
        "id": "f6f21ec6"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "root = \"/home/ogallo/DL4CV/DigitalTyphoon\"\n",
        "\n",
        "dataset = DigitalTyphoon(\n",
        "    root=root,\n",
        "    features=[\"wind\", \"pressure\"],\n",
        "    targets=[\"wind\", \"pressure\"],\n",
        "    sequence_length=1,\n",
        "    download=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e74c63c4",
      "metadata": {
        "id": "e74c63c4",
        "outputId": "e9563ca1-6182-4e1e-a55b-b67061bc0b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       id                   image_path  year  month  day  hour  grade    lat  \\\n",
            "0  197830  1978120100-197830-GMS1-1.h5  1978     12    1     0      6  36.00   \n",
            "1  197830  1978120103-197830-GMS1-1.h5  1978     12    1     3      6  37.46   \n",
            "2  197830  1978120106-197830-GMS1-1.h5  1978     12    1     6      6  39.00   \n",
            "3  197901  1978123112-197901-GMS1-1.h5  1978     12   31    12      2   2.00   \n",
            "4  197901  1978123116-197901-GMS1-1.h5  1978     12   31    16      2   2.30   \n",
            "\n",
            "      lng  pressure  wind  dir50  long50  short50  dir30  long30  short30  \\\n",
            "0  174.00     996.0   0.0      0       0        0      0       0        0   \n",
            "1  176.44     994.0   0.0      0       0        0      0       0        0   \n",
            "2  179.00     992.0   0.0      0       0        0      0       0        0   \n",
            "3  172.00    1004.0   0.0      0       0        0      0       0        0   \n",
            "4  171.81    1002.7   0.0      0       0        0      0       0        0   \n",
            "\n",
            "   landfall  intp  \n",
            "0         0     0  \n",
            "1         0     1  \n",
            "2         0     0  \n",
            "3         0     0  \n",
            "4         0     1  \n"
          ]
        }
      ],
      "source": [
        "aux_data = pd.read_csv(\"/home/ogallo/DL4CV/DigitalTyphoon/WP/aux_data.csv\")\n",
        "print(aux_data.head())     # inspect auxiliary data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d76f04",
      "metadata": {
        "id": "75d76f04"
      },
      "source": [
        "#### Subset the dataset\n",
        "This is based on the typhoon event. We choose 1% of the typhoons i.e. 100 and then stratify teh images based on grade and lifecycle??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64f6ec0",
      "metadata": {
        "id": "b64f6ec0",
        "outputId": "76720e35-4a28-49fd-e09e-a503fd9e1f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 189364 records from 1099 typhoons.\n",
            "Year range: 1978 - 2022\n",
            "\n",
            "Selected 110 typhoons.\n",
            "Sampled 18686 images across 110 typhoons.\n",
            "\n",
            "Copied 18686/18686 images.\n",
            "Saved aux_data.csv\n",
            "Copied and filtered metadata.\n"
          ]
        }
      ],
      "source": [
        "# Import the sampling functions\n",
        "from sample_v2 import load_data, sample_typhoons, sample_images, copy_images, save_sampled_data, copy_metadata\n",
        "\n",
        "# Set paths and parameters\n",
        "root = \"/home/ogallo/DL4CV/DigitalTyphoon/WP\"\n",
        "output_dir = \"/home/ogallo/DL4CV/WP_sampled_10pct\"\n",
        "total_typhoons = 110\n",
        "\n",
        "# Load data\n",
        "df = load_data(root)\n",
        "print(f\"Loaded {len(df)} records from {df['id'].nunique()} typhoons.\")\n",
        "print(f\"Year range: {df['year'].min()} - {df['year'].max()}\")\n",
        "\n",
        "# Sample typhoons (distributed across years)\n",
        "sampled_typhoons = sample_typhoons(df, total_typhoons, seed=42)\n",
        "print(f\"\\nSelected {len(sampled_typhoons)} typhoons.\")\n",
        "\n",
        "# Sample all images for selected typhoons (no cap)\n",
        "df_sampled = sample_images(df, sampled_typhoons)\n",
        "print(f\"Sampled {len(df_sampled)} images across {df_sampled['id'].nunique()} typhoons.\")\n",
        "\n",
        "# Copy images\n",
        "copied, not_found = copy_images(df_sampled, root, output_dir)\n",
        "print(f\"\\nCopied {copied}/{len(df_sampled)} images.\")\n",
        "if not_found:\n",
        "    print(f\"Warning: {len(not_found)} images not found.\")\n",
        "\n",
        "# Save sampled data\n",
        "save_sampled_data(df_sampled, output_dir)\n",
        "print(f\"Saved aux_data.csv\")\n",
        "\n",
        "# Copy metadata\n",
        "sampled_typhoon_ids = sorted(df_sampled['id'].unique())\n",
        "copy_metadata(root, output_dir, sampled_typhoon_ids)\n",
        "print(f\"Copied and filtered metadata.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## start colab"
      ],
      "metadata": {
        "id": "zFN1RNP9NgUI"
      },
      "id": "zFN1RNP9NgUI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58e3e00",
      "metadata": {
        "id": "b58e3e00"
      },
      "outputs": [],
      "source": [
        "dataset = DigitalTyphoon(\n",
        "    root=\"/content/drive/MyDrive/DL4CV/WP_sampled_10pct\",\n",
        "    features=[\"wind\", \"pressure\"],\n",
        "    targets=[\"wind\", \"pressure\"],\n",
        "    sequence_length=1,\n",
        "    download=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__len__\n",
        "dataset.__getitem__(index=0)"
      ],
      "metadata": {
        "id": "xhvkNVf2n0nU"
      },
      "id": "xhvkNVf2n0nU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample = dataset.__getitem__(index=0)\n",
        "# dataset.plot(sample)"
      ],
      "metadata": {
        "id": "CU2Yg74DbRjP"
      },
      "id": "CU2Yg74DbRjP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b01fb31-7d71-43e8-a7f5-8c564df0025d",
      "metadata": {
        "trusted": true,
        "id": "6b01fb31-7d71-43e8-a7f5-8c564df0025d"
      },
      "outputs": [],
      "source": [
        "# visualize input\n",
        "aux_df = pd.read_csv(\"/content/drive/MyDrive/DL4CV/WP_sampled_10pct/WP/aux_data.csv\")\n",
        "aux_df = aux_df.reset_index(drop=True)\n",
        "\n",
        "# random indices\n",
        "indices = np.random.choice(len(dataset), size=4, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 4))\n",
        "for i, idx in enumerate(indices):\n",
        "    sample = dataset[idx]\n",
        "    image = sample['image'].squeeze()\n",
        "    wind = sample['wind']\n",
        "    pressure = sample['pressure']\n",
        "\n",
        "    row = aux_df.iloc[idx] # Lookup metadata from aux_df\n",
        "    typhoon_id = row['id']\n",
        "    grade = row['grade']\n",
        "\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.imshow(image, cmap='viridis')\n",
        "    plt.title(f\"Typhoon:{typhoon_id}, Grade:{grade}\")\n",
        "    plt.suptitle(f\"Wind:{wind:.3f}, Pressure:{pressure:.3f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958fbee7-90f4-4f3f-88b1-8b84d1ad2be9",
      "metadata": {
        "id": "958fbee7-90f4-4f3f-88b1-8b84d1ad2be9"
      },
      "source": [
        "### ResNet50\n",
        "understand and explain model architecture with 2 head for multitask regression (add pic/infograph if possible)\n",
        "\n",
        "in markdown also include what we will do train, val and test then tuning???\n",
        " we resize from 512x512 to 224x224 , resnet default + memory issues\n",
        "\n",
        "**wandb logger?? torchgeo.logger......"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424d19d7-eeaf-4b93-b3fc-a9ddf8e52e80",
      "metadata": {
        "trusted": true,
        "id": "424d19d7-eeaf-4b93-b3fc-a9ddf8e52e80"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)                # CPU\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)       # Single GPU\n",
        "        torch.cuda.manual_seed_all(seed)   # Multi-GPU\n",
        "set_seed(42)\n",
        "\n",
        "# Make CUDA deterministic\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Prep: normalize data and resize images"
      ],
      "metadata": {
        "id": "s6HTXAbae7xM"
      },
      "id": "s6HTXAbae7xM"
    },
    {
      "cell_type": "code",
      "source": [
        "# compute stats\n",
        "def compute_and_save_stats(dataset, target_names, save_path=\"/content/drive/MyDrive/DL4CV/WP_sampled_10pct/digital_typhoon_stats.pt\"):\n",
        "    stats = {name: [] for name in target_names}\n",
        "\n",
        "    # Running mean/std for IR images\n",
        "    count = 0\n",
        "    mean = 0.0\n",
        "    m2 = 0.0\n",
        "\n",
        "    resize = Resize((224, 224))  # resize for faster stats computation\n",
        "\n",
        "    for sample in dataset:\n",
        "        # Targets\n",
        "        for name in target_names:\n",
        "            stats[name].append(sample[name])\n",
        "\n",
        "        # Image: resize to 224x224 to reduce compute\n",
        "        img = resize(sample[\"image\"]).float()\n",
        "        pixels = img.numel()\n",
        "        img_mean = img.mean()\n",
        "        img_var = img.var(unbiased=False)\n",
        "\n",
        "        # Online update\n",
        "        delta = img_mean - mean\n",
        "        mean += delta * pixels / (count + pixels)\n",
        "        m2 += img_var * pixels + delta**2 * count * pixels / (count + pixels)\n",
        "        count += pixels\n",
        "\n",
        "    # Final IR stats\n",
        "    ir_mean = mean\n",
        "    ir_std = (m2 / count)**0.5\n",
        "\n",
        "    # Targets\n",
        "    for name in target_names:\n",
        "        vals = torch.tensor(stats[name], dtype=torch.float32)\n",
        "        stats[name] = {\"mean\": vals.mean(), \"std\": vals.std()}\n",
        "\n",
        "    # Save stats\n",
        "    stats_dict = {\n",
        "        \"target_stats\": stats,\n",
        "        \"ir_mean\": ir_mean,\n",
        "        \"ir_std\": ir_std\n",
        "    }\n",
        "    torch.save(stats_dict, save_path)\n",
        "\n",
        "    return stats, ir_mean, ir_std\n",
        "\n",
        "\n",
        "def load_stats(save_path=\"digital_typhoon_stats.pt\"):\n",
        "    stats_dict = torch.load(save_path)\n",
        "    return stats_dict[\"target_stats\"], stats_dict[\"ir_mean\"], stats_dict[\"ir_std\"]\n",
        "\n",
        "# resize from 512x512\n",
        "def make_transforms(target_stats, ir_mean, ir_std):\n",
        "    resize = Resize((224, 224))\n",
        "\n",
        "    def normalize_targets(sample):\n",
        "        sample[\"wind\"] = (sample[\"wind\"] - target_stats[\"wind\"][\"mean\"]) / (target_stats[\"wind\"][\"std\"] + 1e-6)\n",
        "        sample[\"pressure\"] = (sample[\"pressure\"] - target_stats[\"pressure\"][\"mean\"]) / (target_stats[\"pressure\"][\"std\"] + 1e-6)\n",
        "        return sample\n",
        "\n",
        "    def transform_sample(sample):\n",
        "        img = sample[\"image\"]\n",
        "        img = resize(img)\n",
        "        img = (img - ir_mean) / (ir_std + 1e-6)\n",
        "        if img.shape[0] == 1:\n",
        "            img = img.repeat(3, 1, 1)\n",
        "        sample[\"image\"] = img\n",
        "        sample = normalize_targets(sample)\n",
        "        return sample\n",
        "\n",
        "    return transform_sample\n",
        "\n",
        "# Compute and save stats (once)\n",
        "target_names = [\"wind\", \"pressure\"]\n",
        "target_stats, ir_mean, ir_std = compute_and_save_stats(dataset, target_names)\n",
        "\n",
        "# load stats\n",
        "# target_stats, ir_mean, ir_std = load_stats()\n",
        "\n",
        "# Make transforms\n",
        "transform = make_transforms(target_stats, ir_mean, ir_std)\n"
      ],
      "metadata": {
        "id": "vzeDY9Wse5xW"
      },
      "id": "vzeDY9Wse5xW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize datasets\n",
        "datamodule = DigitalTyphoonDataModule(split_by='typhoon_id',\n",
        "                                      batch_size=16,\n",
        "                                      num_workers=0,\n",
        "                                      download = False,\n",
        "                                      root = \"/content/drive/MyDrive/DL4CV/WP_sampled_10pct\",\n",
        "                                      task = \"regression\",\n",
        "                                      features=[\"wind\", \"pressure\"],\n",
        "                                      targets=[\"wind\", \"pressure\"],\n",
        "                                      sequence_length=1,\n",
        "                                      transforms = transform\n",
        "                                      )"
      ],
      "metadata": {
        "id": "GLmVKs7s1LZl"
      },
      "id": "GLmVKs7s1LZl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = datamodule.train_dataset[0]\n",
        "print(\"Image shape:\", sample[\"image\"].shape)       # [3, 224, 224]\n",
        "print(\"Targets (normalized):\", sample[\"targets\"]) # ~0 mean, ~1 std"
      ],
      "metadata": {
        "id": "ubHxKvtzqWgN"
      },
      "id": "ubHxKvtzqWgN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train base model with deafult parameters"
      ],
      "metadata": {
        "id": "6sT2XtxP4A-3"
      },
      "id": "6sT2XtxP4A-3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "hyperparameter tuning using optuna MSE loss etc"
      ],
      "metadata": {
        "id": "h5Qsa_924c7d"
      },
      "id": "h5Qsa_924c7d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning using optuna\n"
      ],
      "metadata": {
        "id": "XLQ8v1qQ4KBJ"
      },
      "id": "XLQ8v1qQ4KBJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, val metrics plot?"
      ],
      "metadata": {
        "id": "9LDhdWNG4SSd"
      },
      "id": "9LDhdWNG4SSd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference/evaluate on test"
      ],
      "metadata": {
        "id": "pUuDCwmu4UDg"
      },
      "id": "pUuDCwmu4UDg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}