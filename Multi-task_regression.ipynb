{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343d83c4",
   "metadata": {},
   "source": [
    "### Deep Learning for Computer Vision  \n",
    "### Multi-Task Regression with the Digital Typhoon Dataset\n",
    "\n",
    "This notebook demonstrates a **supervised multi-task regression** workflow for remote sensing using **TorchGeo** using the Digital Typhoon dataset, which consists of infrared (IR) satellite imagery of tropical cyclones paired with meteorological measurements.\n",
    "\n",
    "The objective is to predict multiple continuous typhoon intensity variables from satellite imagery using a deep learning model.  \n",
    "\n",
    "#### Dataset Overview\n",
    "The [Digital Typhoon](https://torchgeo.readthedocs.io/en/stable/api/datasets.html#digital-typhoon) is derived from hourly infrared channel observations captured by multiple generations of the Himawari meteorological satellites, spanning the period from 1978 to the present. The satellite measurements have been converted to brightness temperatures and normalized across different sensors, resulting in a consistent spatio-temporal dataset covering more than four decades.  \n",
    "\n",
    "**Dataset features:**\n",
    "- Infrared (IR) satellite imagery of 512 Ã— 512 pixels at ~5km resolution \n",
    "- Auxiliary metadata including wind speed, pressure and additional typhoon-related attributes  \n",
    "- 1,099 typhoons and 189,364 images\n",
    "\n",
    "**References**  \n",
    "Digital Typhoon Dataset: *A Large-Scale Benchmark for Tropical Cyclone Analysis*      [arXiv:2411.16421](https://arxiv.org/pdf/2411.16421) ; [arXiv:2311.02665](https://arxiv.org/pdf/2311.02665)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfcd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import DigitalTyphoon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f21ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "root = \"/home/ogallo/DL4CV/DigitalTyphoon\"\n",
    "\n",
    "dataset = DigitalTyphoon(\n",
    "    root=root,\n",
    "    features=[\"wind\", \"pressure\"],\n",
    "    targets=[\"wind\", \"pressure\"],\n",
    "    sequence_length=1,\n",
    "    download=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc18a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173418\n",
      "{'image': tensor([[[0.7248, 0.7813, 0.7813,  ..., 0.9331, 0.9363, 0.9331],\n",
      "         [0.7248, 0.7576, 0.7735,  ..., 0.9331, 0.9331, 0.9331],\n",
      "         [0.7290, 0.7536, 0.7656,  ..., 0.9299, 0.9299, 0.9331],\n",
      "         ...,\n",
      "         [0.6904, 0.6495, 0.6007,  ..., 0.8483, 0.8798, 0.8659],\n",
      "         [0.6542, 0.6400, 0.6725,  ..., 0.8483, 0.8659, 0.8447],\n",
      "         [0.7373, 0.7536, 0.7967,  ..., 0.8518, 0.8518, 0.8483]]]), 'wind': tensor(-1.1229), 'pressure': tensor(0.5422), 'label': tensor([-1.1229,  0.5422])}\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))        # number of sequences\n",
    "print(dataset[0])          # inspect the first sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74c63c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                   image_path  year  month  day  hour  grade    lat  \\\n",
      "0  197830  1978120100-197830-GMS1-1.h5  1978     12    1     0      6  36.00   \n",
      "1  197830  1978120103-197830-GMS1-1.h5  1978     12    1     3      6  37.46   \n",
      "2  197830  1978120106-197830-GMS1-1.h5  1978     12    1     6      6  39.00   \n",
      "3  197901  1978123112-197901-GMS1-1.h5  1978     12   31    12      2   2.00   \n",
      "4  197901  1978123116-197901-GMS1-1.h5  1978     12   31    16      2   2.30   \n",
      "\n",
      "      lng  pressure  wind  dir50  long50  short50  dir30  long30  short30  \\\n",
      "0  174.00     996.0   0.0      0       0        0      0       0        0   \n",
      "1  176.44     994.0   0.0      0       0        0      0       0        0   \n",
      "2  179.00     992.0   0.0      0       0        0      0       0        0   \n",
      "3  172.00    1004.0   0.0      0       0        0      0       0        0   \n",
      "4  171.81    1002.7   0.0      0       0        0      0       0        0   \n",
      "\n",
      "   landfall  intp  \n",
      "0         0     0  \n",
      "1         0     1  \n",
      "2         0     0  \n",
      "3         0     0  \n",
      "4         0     1  \n"
     ]
    }
   ],
   "source": [
    "aux_data = pd.read_csv(\"/home/ogallo/DL4CV/DigitalTyphoon/WP/aux_data.csv\")\n",
    "print(aux_data.head())     # inspect auxiliary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0216a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1978, 1979, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
       "       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n",
       "       2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n",
       "       2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_data['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d76f04",
   "metadata": {},
   "source": [
    "Subset the dataset based on the typhoon grade, number of typhoons and lifecycle??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7ad461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 30 typhoons\n"
     ]
    }
   ],
   "source": [
    "# sampling startegy\n",
    "import numpy as np\n",
    "\n",
    "root = \"/home/ogallo/DL4CV/DigitalTyphoon/WP\"\n",
    "output_dir = \"/home/ogallo/DL4CV/WP\"\n",
    "total_typhoons = 30\n",
    "max_total_images = 1500\n",
    "np.random.seed(42)\n",
    "\n",
    "# load auxiliary data\n",
    "aux_path = os.path.join(root, \"aux_data.csv\")\n",
    "df = pd.read_csv(aux_path)\n",
    "\n",
    "\n",
    "# Aggregate to get first year and peak grade per typhoon\n",
    "typhoon_info = df.groupby('id').agg({\n",
    "    'year': 'min',\n",
    "    'grade': 'max'\n",
    "}).reset_index().rename(columns={'year':'first_year', 'grade':'peak_grade'})\n",
    "\n",
    "# Stratify by years\n",
    "all_years = sorted(typhoon_info['first_year'].unique())\n",
    "\n",
    "# Create target years - evenly distributed\n",
    "num_years = len(all_years)\n",
    "step = max(1, num_years // total_typhoons)\n",
    "target_year_indices = list(range(0, num_years, step))[:total_typhoons]\n",
    "target_years = [all_years[i] for i in target_year_indices]\n",
    "\n",
    "sampled_typhoons = []\n",
    "\n",
    "for year in target_years:\n",
    "    candidates = typhoon_info[typhoon_info['first_year'] == year]\n",
    "    if len(candidates) > 0:\n",
    "        selected = candidates.iloc[0]\n",
    "        sampled_typhoons.append(int(selected['id']))\n",
    "\n",
    "print(f\"Selected {len(sampled_typhoons)} typhoons\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3debadc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 1,380\n",
      "Unique typhoons: 30\n",
      "Unique years: 30\n"
     ]
    }
   ],
   "source": [
    "# Sample images per typhoon\n",
    "\n",
    "all_sampled_rows = []\n",
    "\n",
    "for typhoon_id in sampled_typhoons:\n",
    "    # Get ALL rows for this typhoon from the original dataframe\n",
    "    typhoon_data = df[df['id'] == typhoon_id].copy()\n",
    "    typhoon_data = typhoon_data.sort_values(['year','month','day','hour']).reset_index(drop=True)\n",
    "    n_images = len(typhoon_data)\n",
    "    \n",
    "    \n",
    "    # How many images to sample per typhoon\n",
    "    n_sample = min(n_images, max(5, int(max_total_images / total_typhoons)))\n",
    "    \n",
    "    if n_images <= n_sample:\n",
    "        # Take all images if we have fewer than target\n",
    "        sampled_rows = typhoon_data\n",
    "    else:\n",
    "        # Sample lifecycle stages\n",
    "        peak_idx = typhoon_data['grade'].idxmax()\n",
    "        early_idx = 0\n",
    "        decay_idx = max(0, n_images - 1)\n",
    "        \n",
    "        sampled_indices = {early_idx, peak_idx, decay_idx}\n",
    "        \n",
    "        # Fill remaining randomly\n",
    "        remaining = n_sample - len(sampled_indices)\n",
    "        if remaining > 0:\n",
    "            available = list(set(range(n_images)) - sampled_indices)\n",
    "            if len(available) > 0:\n",
    "                additional = np.random.choice(available, size=min(remaining, len(available)), replace=False)\n",
    "                sampled_indices.update(additional)\n",
    "        \n",
    "        sampled_rows = typhoon_data.iloc[list(sampled_indices)]\n",
    "    \n",
    "    all_sampled_rows.append(sampled_rows)\n",
    "\n",
    "# Concatenate all sampled rows\n",
    "df_sampled = pd.concat(all_sampled_rows, ignore_index=True)\n",
    "\n",
    "print(f\"Total images: {len(df_sampled):,}\")\n",
    "print(f\"Unique typhoons: {df_sampled['id'].nunique()}\")\n",
    "print(f\"Unique years: {df_sampled['year'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7d2326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copied 1380/1380 files\n",
      "\n",
      "Saved aux_data.csv to /home/ogallo/DL4CV/WP\n"
     ]
    }
   ],
   "source": [
    "# Copy sample images to output directory\n",
    "images_src_dir = os.path.join(root, \"image\")\n",
    "images_dst_dir = os.path.join(output_dir, \"image\")\n",
    "os.makedirs(images_dst_dir, exist_ok=True)\n",
    "\n",
    "copied = 0\n",
    "not_found = []\n",
    "\n",
    "for idx, row in df_sampled.iterrows():\n",
    "    img_file = row['image_path']\n",
    "    found = False\n",
    "    \n",
    "    for root_dir, dirs, files in os.walk(images_src_dir):\n",
    "        if img_file in files:\n",
    "            src = os.path.join(root_dir, img_file)\n",
    "            rel_path = os.path.relpath(root_dir, images_src_dir)\n",
    "            dst = os.path.join(images_dst_dir, rel_path, img_file)\n",
    "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "            shutil.copy2(src, dst)\n",
    "            copied += 1\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        not_found.append(img_file)\n",
    "    \n",
    "\n",
    "print(f\"\\nCopied {copied}/{len(df_sampled)} files\")\n",
    "if not_found:\n",
    "    print(f\"Warning: {len(not_found)} files not found\")\n",
    "\n",
    "# Save CSV\n",
    "output_csv = os.path.join(output_dir, \"aux_data.csv\")\n",
    "df_sampled.to_csv(output_csv, index=False)\n",
    "print(f\"\\nSaved aux_data.csv to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b58e3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.datasets import DigitalTyphoon\n",
    "dataset2 = DigitalTyphoon(\n",
    "    root=\"/home/ogallo/DL4CV\",\n",
    "    features=[\"wind\", \"pressure\"],\n",
    "    targets=[\"wind\", \"pressure\"],\n",
    "    sequence_length=1,\n",
    "    download=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
